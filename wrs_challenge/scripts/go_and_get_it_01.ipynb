{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "sudo apt-get update && sudo apt-get install -y ros-melodic-rospy-message-converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "pip install scipy scikit-learn colour shapely aabbtree future matplotlib opencv-contrib-python==4.0.0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash --bg\n",
    "rviz -d /workspace/notebooks/data/3_navigation.rviz > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tf\n",
    "\n",
    "import sys\n",
    "\n",
    "import rospy\n",
    "rospy.init_node(\"go_and_get_it_01\")\n",
    "\n",
    "\n",
    "# Wait for Gazebo to actually properly start...\n",
    "import time\n",
    "while rospy.Time.now() == rospy.Time():\n",
    "    rospy.loginfo(\"Simulation paused/stalled\")\n",
    "    time.sleep(0.1)\n",
    "rospy.loginfo(\"Simulation started\")\n",
    "    \n",
    "from rospy_message_converter import json_message_converter\n",
    "\n",
    "\n",
    "from geometry_msgs.msg import Pose, PointStamped\n",
    "\n",
    "from shapely.geometry import MultiPoint, Polygon\n",
    "\n",
    "\n",
    "import utils\n",
    "\n",
    "robot = utils.Robot()\n",
    "scene = utils.Scene(start_on_init=False)\n",
    "message_parser = utils.MessageParser()\n",
    "\n",
    "rospy.loginfo(\"Imports done, robot initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.NavGoalToJsonFileSaver(\"saved_msg.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved_msg.json\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beside_bins_goal_str = '{\"header\": {\"stamp\": {\"secs\": 182, \"nsecs\": 889000000}, \"frame_id\": \"\", \"seq\": 1}, \"goal_id\": {\"stamp\": {\"secs\": 0, \"nsecs\": 0}, \"id\": \"\"}, \"goal\": {\"target_pose\": {\"header\": {\"stamp\": {\"secs\": 182, \"nsecs\": 889000000}, \"frame_id\": \"map\", \"seq\": 1}, \"pose\": {\"position\": {\"y\": 0.31022635102272034, \"x\": 2.4421634674072266, \"z\": 0.0}, \"orientation\": {\"y\": 0.0, \"x\": 0.0, \"z\": -0.0026041090858226357, \"w\": 0.9999966093021861}}}}}' \n",
    "beside_bins_goal = json_message_converter.convert_json_to_ros_message('move_base_msgs/MoveBaseActionGoal', beside_bins_goal_str).goal\n",
    "\n",
    "rospy.loginfo(\"Sending first goal\")\n",
    "robot.move_base_actual_goal(beside_bins_goal)\n",
    "rospy.loginfo(\"First goal sent\")\n",
    "\n",
    "beside_bins_turn_goal_str = '{\"header\": {\"stamp\": {\"secs\": 208, \"nsecs\": 770000000}, \"frame_id\": \"\", \"seq\": 2}, \"goal_id\": {\"stamp\": {\"secs\": 0, \"nsecs\": 0}, \"id\": \"\"}, \"goal\": {\"target_pose\": {\"header\": {\"stamp\": {\"secs\": 208, \"nsecs\": 743000000}, \"frame_id\": \"map\", \"seq\": 2}, \"pose\": {\"position\": {\"y\": 0.4013778567314148, \"x\": 2.4725470542907715, \"z\": 0.0}, \"orientation\": {\"y\": 0.0, \"x\": 0.0, \"z\": 0.7055942189706708, \"w\": 0.7086161148006508}}}}}' \n",
    "beside_bins_turn_goal = json_message_converter.convert_json_to_ros_message('move_base_msgs/MoveBaseActionGoal', beside_bins_turn_goal_str).goal\n",
    "\n",
    "robot.move_base_actual_goal(beside_bins_turn_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstacle_avoidance_area_goal_str = '{\"header\": {\"stamp\": {\"secs\": 1218, \"nsecs\": 867000000}, \"frame_id\": \"\", \"seq\": 21}, \"goal_id\": {\"stamp\": {\"secs\": 0, \"nsecs\": 0}, \"id\": \"\"}, \"goal\": {\"target_pose\": {\"header\": {\"stamp\": {\"secs\": 1218, \"nsecs\": 867000000}, \"frame_id\": \"map\", \"seq\": 21}, \"pose\": {\"position\": {\"y\": 1.7440035343170166, \"x\": 2.618055582046509, \"z\": 0.0}, \"orientation\": {\"y\": 0.0, \"x\": 0.0, \"z\": 0.7167735161966976, \"w\": 0.697306049363565}}}}}'\n",
    "obstacle_avoidance_area_goal = json_message_converter.convert_json_to_ros_message('move_base_msgs/MoveBaseActionGoal', obstacle_avoidance_area_goal_str).goal\n",
    "\n",
    "robot.move_base_actual_goal(obstacle_avoidance_area_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.move_head_tilt(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_objects = scene.wait_for_one_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_obj_list_by_distance(cur_objects):\n",
    "    robot.tf_listener.waitForTransform(\"map\", \"base_link\", rospy.Time(0),rospy.Duration(4.0))\n",
    "    robot_transform = robot.tf_listener.lookupTransform(\"map\", \"base_link\", rospy.Time(0))\n",
    "    robot_pose_in_map = robot_transform[0][0], robot_transform[0][1], math.degrees(tf.transformations.euler_from_quaternion(robot_transform[1])[2])\n",
    "\n",
    "    uid_by_distance = []\n",
    "    uid_to_convex_footprint = {}\n",
    "    for uid, obj in cur_objects.items():\n",
    "        convex_footprint = MultiPoint(obj.bb_coords_2d).convex_hull    \n",
    "        if convex_footprint.intersects(utils.TABOO_AREA_POLYGON):\n",
    "            min_distance = float(\"inf\")\n",
    "            for coord in obj.bb_coords_2d:\n",
    "                min_distance = min(min_distance, utils.euclidean_distance(coord, robot_pose_in_map))\n",
    "            uid_by_distance.append((uid, min_distance))\n",
    "            uid_to_convex_footprint[uid] = convex_footprint\n",
    "    uid_by_distance = sorted(uid_by_distance, key=lambda tup: tup[1])\n",
    "    return uid_by_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_by_distance = get_sorted_obj_list_by_distance(current_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_object_away(obj):    \n",
    "    # Compute angle for robot base to face arm parallel direction between base_link and object\n",
    "    o_x, o_y = robot.get_diff_between(\"base_link\", obj.name)\n",
    "    yaw = math.pi/2. - math.atan2(o_x, o_y)\n",
    "\n",
    "    joints_for_facing_object = robot.base.get_current_joint_values()\n",
    "    joints_for_facing_object[2] += yaw\n",
    "\n",
    "    robot.base.set_joint_value_target(joints_for_facing_object)\n",
    "    robot.base.go()\n",
    "    \n",
    "    # Set to picking pose\n",
    "    joints_for_arm_picking_from_ground = [0.1] + [math.radians(a) for a in [-107., 0., -73., 0., 0.]]\n",
    "    robot.arm.set_joint_value_target(joints_for_arm_picking_from_ground)\n",
    "    robot.arm.go()\n",
    "    robot.open_hand()\n",
    "    \n",
    "    # Compute translation for robot base to actually face the object\n",
    "    a_x, a_y = robot.get_diff_between(\"base_link\", \"arm_flex_link\")\n",
    "\n",
    "    robot.tf_listener.waitForTransform(\"/base_link\", \"/odom\", rospy.Time(0),rospy.Duration(4.0))\n",
    "    point=PointStamped()\n",
    "    point.header.frame_id = \"base_link\"\n",
    "    point.header.stamp =rospy.Time(0)\n",
    "    point.point.y= -a_y\n",
    "    p=robot.tf_listener.transformPoint(\"odom\", point)\n",
    "\n",
    "    joints_for_going_to_object = robot.base.get_current_joint_values()\n",
    "    joints_for_going_to_object[0] = p.point.y\n",
    "    joints_for_going_to_object[1] = p.point.x\n",
    "\n",
    "    robot.base.set_joint_value_target(joints_for_going_to_object)\n",
    "    robot.base.go()\n",
    "    \n",
    "    # Compute translation for robot base to get the object and get it\n",
    "    oo_x, oo_y = robot.get_diff_between(\"odom\", obj.name)\n",
    "    ho_x, ho_y = robot.get_diff_between(\"odom\", \"hand_palm_link\")\n",
    "\n",
    "    joints_for_catching_to_object = robot.base.get_current_joint_values()\n",
    "    joints_for_catching_to_object[0] += oo_y - ho_y\n",
    "    joints_for_catching_to_object[1] += oo_x - ho_x\n",
    "\n",
    "    robot.base.set_joint_value_target(joints_for_catching_to_object)\n",
    "    robot.base.go()\n",
    "    \n",
    "    # Lower arm\n",
    "    joints_for_lower_arm_picking_from_ground = robot.arm.get_current_joint_values()\n",
    "    joints_for_lower_arm_picking_from_ground[0] = 0.\n",
    "    robot.arm.set_joint_value_target(joints_for_lower_arm_picking_from_ground)\n",
    "    robot.arm.go()\n",
    "    \n",
    "    # Pick\n",
    "    robot.close_hand()\n",
    "    \n",
    "    # Move arm up\n",
    "    robot.arm.set_joint_value_target(joints_for_arm_picking_from_ground)\n",
    "    robot.arm.go()\n",
    "    \n",
    "    # Keep it close to your heart\n",
    "    robot.move_arm_init()\n",
    "    \n",
    "    if robot.is_hand_fully_closed():\n",
    "        return False\n",
    "    \n",
    "    # Turn 180deg\n",
    "    joints_turn_180_deg = robot.base.get_current_joint_values()\n",
    "    joints_turn_180_deg[2] -= math.radians(180)\n",
    "    robot.base.set_joint_value_target(joints_turn_180_deg)\n",
    "    robot.base.go()\n",
    "    \n",
    "    # Deliver\n",
    "    robot.arm.set_joint_value_target(joints_for_arm_picking_from_ground)\n",
    "    robot.arm.go()\n",
    "    robot.open_hand()\n",
    "    robot.shake_wrist()\n",
    "    \n",
    "    # Reset arm pose\n",
    "    robot.move_arm_init()\n",
    "    robot.close_hand()\n",
    "    \n",
    "    # Turn 180deg again\n",
    "    joints_turn_180_deg = robot.base.get_current_joint_values()\n",
    "    joints_turn_180_deg[2] += math.radians(180)\n",
    "    robot.base.set_joint_value_target(joints_turn_180_deg)\n",
    "    robot.base.go()\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial base joints\n",
    "joints_for_going_back = robot.base.get_current_joint_values()\n",
    "\n",
    "is_object_moved = True\n",
    "for (uid, _) in uid_by_distance:\n",
    "    obj = current_objects[uid]\n",
    "    is_object_moved = pick_object_away(obj)\n",
    "    joints_for_going_back = robot.base.get_current_joint_values()\n",
    "    if not is_object_moved:\n",
    "        break\n",
    "if not is_object_moved:\n",
    "    robot.base.set_joint_value_target(joints_for_going_back)\n",
    "    robot.base.go()\n",
    "    current_objects = scene.wait_for_one_detection()\n",
    "    uid_by_distance = get_sorted_obj_list_by_distance(current_objects)\n",
    "    for (uid, _) in uid_by_distance:\n",
    "        obj = current_objects[uid]\n",
    "        pick_object_away(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.move_arm_init()\n",
    "robot.close_hand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.move_head_tilt(-0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_room_02_goal_str = '{\"header\": {\"stamp\": {\"secs\": 688, \"nsecs\": 512000000}, \"frame_id\": \"\", \"seq\": 11}, \"goal_id\": {\"stamp\": {\"secs\": 0, \"nsecs\": 0}, \"id\": \"\"}, \"goal\": {\"target_pose\": {\"header\": {\"stamp\": {\"secs\": 688, \"nsecs\": 512000000}, \"frame_id\": \"map\", \"seq\": 11}, \"pose\": {\"position\": {\"y\": 2.9992051124572754, \"x\": 2.3737993240356445, \"z\": 0.0}, \"orientation\": {\"y\": 0.0, \"x\": 0.0, \"z\": 0.7056854446361143, \"w\": 0.708525266471655}}}}}'\n",
    "enter_room_02_goal = json_message_converter.convert_json_to_ros_message('move_base_msgs/MoveBaseActionGoal', enter_room_02_goal_str).goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.move_base_actual_goal(enter_room_02_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_front_shelf_goal_str = '{\"header\": {\"stamp\": {\"secs\": 607, \"nsecs\": 362000000}, \"frame_id\": \"\", \"seq\": 6}, \"goal_id\": {\"stamp\": {\"secs\": 0, \"nsecs\": 0}, \"id\": \"\"}, \"goal\": {\"target_pose\": {\"header\": {\"stamp\": {\"secs\": 607, \"nsecs\": 353000000}, \"frame_id\": \"map\", \"seq\": 6}, \"pose\": {\"position\": {\"y\": 3.7436118125915527, \"x\": 2.2750515937805176, \"z\": 0.0}, \"orientation\": {\"y\": 0.0, \"x\": 0.0, \"z\": 0.7071067966408575, \"w\": 0.7071067657322372}}}}}'\n",
    "in_front_shelf_goal = json_message_converter.convert_json_to_ros_message('move_base_msgs/MoveBaseActionGoal', in_front_shelf_goal_str).goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.move_base_actual_goal(in_front_shelf_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.move_head_tilt(-0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_objects = scene.wait_for_one_detection(use_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chosen_object(cur_objects):\n",
    "\n",
    "    chosen_object = None\n",
    "\n",
    "    # Prioritize choosing objects that look like the required one\n",
    "    required_label = message_parser.get_object_darknet()\n",
    "    if required_label:\n",
    "        rospy.loginfo(\"Object to be delivered is: {}\".format(required_label))\n",
    "\n",
    "    # Choose closest object that fits in robot's hand by default otherwise\n",
    "    uid_by_distance = []\n",
    "    for uid, obj in cur_objects.items():\n",
    "        convex_footprint = MultiPoint(obj.bb_coords_2d).convex_hull\n",
    "        if isinstance(convex_footprint, Polygon):\n",
    "            obj_radius = utils.get_circumscribed_radius(convex_footprint)\n",
    "        else:\n",
    "            obj_radius = 0.00000000001\n",
    "        if obj_radius <= robot.GRASP_RADIUS:\n",
    "            x, _= robot.get_diff_between(\"base_link\", obj.name)\n",
    "            uid_by_distance.append((uid, x))\n",
    "            if required_label and obj.label == required_label:\n",
    "                chosen_object = obj\n",
    "\n",
    "    if not chosen_object:\n",
    "        uid_by_distance = sorted(uid_by_distance, key=lambda tup: tup[1])\n",
    "        if uid_by_distance:\n",
    "            chosen_object = cur_objects[uid_by_distance[0][0]]\n",
    "\n",
    "    if not chosen_object:\n",
    "        rospy.logwarn(\"No object was able to be chosen. Stopping robot.\")\n",
    "        sys.exit(0)\n",
    "        \n",
    "    return chosen_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_object = get_chosen_object(current_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_SHELF_LINEAR_JOINT_HEIGHT = 0.21\n",
    "SECOND_SHELF_LINEAR_JOINT_HEIGHT = 0.51\n",
    "SECOND_SHELF_HEIGHT = 0.78\n",
    "\n",
    "def pick_object_from_shelf(obj):\n",
    "    # Identify related shelf\n",
    "    linear_joint_height = SECOND_SHELF_LINEAR_JOINT_HEIGHT if (obj.xyz_med[2] >= SECOND_SHELF_HEIGHT) else FIRST_SHELF_LINEAR_JOINT_HEIGHT\n",
    "    \n",
    "    # Save joints for pose in front of shelf\n",
    "    joints_for_going_back_in_front_shelf = robot.base.get_current_joint_values()\n",
    "    \n",
    "    # Open hand and go to straight arm joints\n",
    "    robot.open_hand()\n",
    "    straight_arm = [linear_joint_height] + [math.radians(a) for a in [-90., 0., 0., 0., 0.]]\n",
    "    robot.arm.set_joint_value_target(straight_arm)\n",
    "    robot.arm.go()\n",
    "    \n",
    "    # Move parallel direction from base link to object\n",
    "    diff_x, diff_y = robot.get_diff_between(\"base_link\", obj.name)\n",
    "    yaw = math.pi/2. - math.atan2(diff_x, diff_y)\n",
    "    math.degrees(yaw)\n",
    "    joints_for_facing_object = robot.base.get_current_joint_values()\n",
    "    joints_for_facing_object[2] += yaw\n",
    "    robot.base.set_joint_value_target(joints_for_facing_object)\n",
    "    robot.base.go()\n",
    "    \n",
    "    # Translate in front of object\n",
    "    a_x, a_y = robot.get_diff_between(\"base_link\", \"arm_flex_link\")\n",
    "    robot.tf_listener.waitForTransform(\"/base_link\", \"/odom\", rospy.Time(0),rospy.Duration(4.0))\n",
    "    point=PointStamped()\n",
    "    point.header.frame_id = \"base_link\"\n",
    "    point.header.stamp =rospy.Time(0)\n",
    "    point.point.y=-a_y\n",
    "    p=robot.tf_listener.transformPoint(\"odom\", point)\n",
    "    joints_for_going_to_object = robot.base.get_current_joint_values()\n",
    "    joints_for_going_to_object[0] = p.point.y\n",
    "    joints_for_going_to_object[1] = p.point.x\n",
    "    robot.base.set_joint_value_target(joints_for_going_to_object)\n",
    "    robot.base.go()\n",
    "    \n",
    "    # Translate to object\n",
    "#     obj_o_x, obj_o_y = robot.get_diff_between(\"odom\", obj.name)\n",
    "#     print(\"obj_o_x, obj_o_y: {}, {}\".format(obj_o_x, obj_o_y))\n",
    "    r_x, r_y = robot.get_diff_between(\"map\", \"hand_palm_link\")\n",
    "#     print(\"r_x, r_y: {}, {}\".format(r_x, r_y))\n",
    "    min_distance_to_robot = float(\"inf\")\n",
    "    nearest_o_x, nearest_o_y = robot.get_diff_between(\"map\", obj.name)\n",
    "#     print(\"nearest_o_x, nearest_o_y: {}, {}\".format(nearest_o_x, nearest_o_y))\n",
    "    for pixel in obj.pixels:\n",
    "        x, y, z = pixel.x, pixel.y, pixel.z\n",
    "        dist = utils.euclidean_distance((r_x, r_y), (x, y))\n",
    "        if dist < min_distance_to_robot:\n",
    "            min_distance_to_robot = dist\n",
    "            nearest_o_x, nearest_o_y, nearest_o_z = x, y, z\n",
    "#     print(\"nearest_o_x, nearest_o_y, nearest_o_z: {}, {}\".format(nearest_o_x, nearest_o_y, nearest_o_z))\n",
    "            \n",
    "    \n",
    "    robot.tf_listener.waitForTransform(\"/odom\", \"/map\", rospy.Time(0),rospy.Duration(4.0))\n",
    "    point=PointStamped()\n",
    "    point.header.frame_id = \"map\"\n",
    "    point.header.stamp =rospy.Time(0)\n",
    "    point.point.x=nearest_o_x\n",
    "    point.point.y=nearest_o_y\n",
    "    point.point.z=nearest_o_z\n",
    "    p=robot.tf_listener.transformPoint(\"odom\", point)\n",
    "    obj_o_x, obj_o_y = p.point.x, p.point.y\n",
    "#     print(\"obj_o_x, obj_o_y: {}, {}\".format(obj_o_x, obj_o_y))\n",
    "    ######\n",
    "    \n",
    "    ho_x, ho_y = robot.get_diff_between(\"odom\", \"hand_palm_link\")\n",
    "    joints_for_catching_to_object = robot.base.get_current_joint_values()\n",
    "    joints_for_catching_to_object[0] += obj_o_y - ho_y\n",
    "    joints_for_catching_to_object[1] += obj_o_x - ho_x\n",
    "    robot.base.set_joint_value_target(joints_for_catching_to_object)\n",
    "    robot.base.go()\n",
    "    \n",
    "    # Pick it\n",
    "    robot.close_hand()\n",
    "    \n",
    "    # Lift it slightly\n",
    "    joints_for_lifting_object = robot.arm.get_current_joint_values()\n",
    "    joints_for_lifting_object[0] += 0.01\n",
    "    robot.arm.set_joint_value_target(joints_for_lifting_object)\n",
    "    robot.arm.go()\n",
    "    \n",
    "    # Move back in front of shelf\n",
    "    joints_for_going_back_in_front_shelf_trans = robot.base.get_current_joint_values()\n",
    "    joints_for_going_back_in_front_shelf_trans[0] = joints_for_going_back_in_front_shelf[0]\n",
    "    joints_for_going_back_in_front_shelf_trans[1] = joints_for_going_back_in_front_shelf[1]\n",
    "    robot.base.set_joint_value_target(joints_for_going_back_in_front_shelf_trans)\n",
    "    robot.base.go()\n",
    "    joints_for_going_back_in_front_shelf_rot = robot.base.get_current_joint_values()\n",
    "    joints_for_going_back_in_front_shelf_rot[2] = joints_for_going_back_in_front_shelf[2]\n",
    "    robot.base.set_joint_value_target(joints_for_going_back_in_front_shelf_rot)\n",
    "    robot.base.go()\n",
    "    \n",
    "    # Keep object close to your heart\n",
    "    robot.move_arm_init()\n",
    "    \n",
    "    if robot.is_hand_fully_closed():\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pick_success = pick_object_from_shelf(chosen_object)\n",
    "if not is_pick_success:\n",
    "    current_objects = scene.wait_for_one_detection(use_labels=True)\n",
    "    chosen_object = get_chosen_object(current_objects)\n",
    "    is_pick_success = pick_object_from_shelf(chosen_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_between_humans_goal_str = '{\"header\": {\"stamp\": {\"secs\": 134, \"nsecs\": 703000000}, \"frame_id\": \"\", \"seq\": 0}, \"goal_id\": {\"stamp\": {\"secs\": 0, \"nsecs\": 0}, \"id\": \"\"}, \"goal\": {\"target_pose\": {\"header\": {\"stamp\": {\"secs\": 134, \"nsecs\": 679000000}, \"frame_id\": \"map\", \"seq\": 0}, \"pose\": {\"position\": {\"y\": 3.857577323913574, \"x\": 1.0511448383331299, \"z\": 0.0}, \"orientation\": {\"y\": 0.0, \"x\": 0.0, \"z\": 0.9999999998344654, \"w\": -1.819530991026369e-05}}}}}'\n",
    "move_between_humans_goal = json_message_converter.convert_json_to_ros_message('move_base_msgs/MoveBaseActionGoal', move_between_humans_goal_str).goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.move_base_actual_goal(move_between_humans_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_human_side_instruction = message_parser.get_person()\n",
    "if latest_human_side_instruction:\n",
    "    rospy.loginfo(\"Object must be delivered to human: {}\".format(latest_human_side_instruction))\n",
    "\n",
    "if latest_human_side_instruction == \"right\":\n",
    "    in_front_human_right_goal_str = '{\"header\": {\"stamp\": {\"secs\": 176, \"nsecs\": 562000000}, \"frame_id\": \"\", \"seq\": 1}, \"goal_id\": {\"stamp\": {\"secs\": 0, \"nsecs\": 0}, \"id\": \"\"}, \"goal\": {\"target_pose\": {\"header\": {\"stamp\": {\"secs\": 176, \"nsecs\": 562000000}, \"frame_id\": \"map\", \"seq\": 1}, \"pose\": {\"position\": {\"y\": 3.909142017364502, \"x\": 0.40349310636520386, \"z\": 0.0}, \"orientation\": {\"y\": 0.0, \"x\": 0.0, \"z\": 0.9999394114821857, \"w\": -0.011007877391217903}}}}}'\n",
    "    in_front_human_right_goal = json_message_converter.convert_json_to_ros_message('move_base_msgs/MoveBaseActionGoal', in_front_human_right_goal_str).goal\n",
    "    robot.move_base_actual_goal(in_front_human_right_goal)\n",
    "    \n",
    "else:\n",
    "    in_front_human_left_goal_str = '{\"header\": {\"stamp\": {\"secs\": 209, \"nsecs\": 613000000}, \"frame_id\": \"\", \"seq\": 2}, \"goal_id\": {\"stamp\": {\"secs\": 0, \"nsecs\": 0}, \"id\": \"\"}, \"goal\": {\"target_pose\": {\"header\": {\"stamp\": {\"secs\": 209, \"nsecs\": 613000000}, \"frame_id\": \"map\", \"seq\": 2}, \"pose\": {\"position\": {\"y\": 2.8555641174316406, \"x\": 0.5514420866966248, \"z\": 0.0}, \"orientation\": {\"y\": 0.0, \"x\": 0.0, \"z\": 0.9999989738094117, \"w\": -0.0014326130403864133}}}}}'\n",
    "    in_front_human_left_goal = json_message_converter.convert_json_to_ros_message('move_base_msgs/MoveBaseActionGoal', in_front_human_left_goal_str).goal\n",
    "    robot.move_base_actual_goal(in_front_human_left_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.move_arm_neutral()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save points published in Rviz, simply use the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = utils.PointsSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = saver.get_coords()\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform saved points in the base_link frame, simply use the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robot.tf_listener.waitForTransform(\"map\", \"base_link\", rospy.Time(0),rospy.Duration(4.0))\n",
    "# transform = robot.tf_listener.lookupTransform(\"map\", \"base_link\", rospy.Time(0))\n",
    "# current_pose = transform[0][0], transform[0][1], math.degrees(tf.transformations.euler_from_quaternion(transform[1])[2])\n",
    "# transformed_coords = []\n",
    "# for coord in saved_robot_coords:\n",
    "#     point=PointStamped()\n",
    "#     point.header.frame_id = \"map\"\n",
    "#     point.header.stamp =rospy.Time(0)\n",
    "#     point.point.x=coord[0]\n",
    "#     point.point.y=coord[1]\n",
    "#     p=robot.tf_listener.transformPoint(\"base_link\", point)\n",
    "#     transformed_coords.append((p.point.x, p.point.y))\n",
    "# transformed_coords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
